{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5dYNT_W8P7u"
      },
      "source": [
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCZRoWupaIr4"
      },
      "source": [
        "##Setting Up The YOLOv5 Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9PDDVZKaQqm"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "!pip install -U -r yolov5/requirements.txt  # install dependencies\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5tG5G6PcErT"
      },
      "source": [
        "#installing for google colab GPU use\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFASNFceaTcR"
      },
      "source": [
        "%cd /content/yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE5SpxqtbKvU"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rUqMm2RbPqR"
      },
      "source": [
        "import torch\n",
        "from IPython.display import Image\n",
        "\n",
        "print('Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3WdQURpdFs2"
      },
      "source": [
        "### Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyR7bDkVcz_O"
      },
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/YRDeArnNYZ?key=7zCCi2Zm26\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yQ2AiKJfhLg"
      },
      "source": [
        "Path to train dataset - /content/yolov5/train \n",
        "\n",
        "Path to test dataset - /content/yolov5/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxXy6UH7f5DT"
      },
      "source": [
        "## Define Model Configuration and Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgulgVLLdWeS"
      },
      "source": [
        "%cat data.yaml\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-yoCEXgj5gY"
      },
      "source": [
        "Path to the train and test dataset is not correct. We need to edit it in the next steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sizDveLZgBta"
      },
      "source": [
        "# define number of classes based on YAML\n",
        "# data.yaml contains number of classes and labels required\n",
        "import yaml\n",
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjucd98vkMmN"
      },
      "source": [
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1Zysve7kP9O"
      },
      "source": [
        "# Change the data configuration for right path to the dataset\n",
        "%%writetemplate /content/yolov5/data.yaml\n",
        "\n",
        "train: ./train/images\n",
        "val: ./valid/images\n",
        "\n",
        "nc: 2\n",
        "names: ['FishRaysKelp', 'Kelp']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFooocmHkh8x"
      },
      "source": [
        "%cat data.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK4C1YDZgNtF"
      },
      "source": [
        "with open(r'data.yaml') as file:\n",
        "    # The FullLoader parameter handles the conversion from YAML\n",
        "    # scalar values to Python the dictionary format\n",
        "    labels_list = yaml.load(file, Loader=yaml.FullLoader)\n",
        "\n",
        "    label_names = labels_list['names']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XSepvKYgP5G"
      },
      "source": [
        "print(\"Number of Classes: {}, Labels: {}\".format(num_classes,label_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8DM4QTSgSxt"
      },
      "source": [
        "# Use yolov5l.yaml configuration for training.\n",
        "%cat /content/yolov5/models/yolov5l.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x71-08y6gkAU"
      },
      "source": [
        "# Change configuration so that it corresponds to number of classes\n",
        "%%writetemplate /content/yolov5/models/custom_yolov5l.yaml\n",
        "\n",
        "# Parameters\n",
        "nc: num_classses  # number of classes\n",
        "depth_multiple: 1.0  # model depth multiple\n",
        "width_multiple: 1.0  # layer channel multiple\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 v6.0 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, C3, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 6, C3, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, C3, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 3, C3, [1024]],\n",
        "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 v6.0 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, C3, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf5e8_HJgtMY"
      },
      "source": [
        "## Train Custom YOLOv5\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxsCCFUSgplE"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/yolov5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb portion is optional\n",
        "!pip install wandb\n",
        "import wandb"
      ],
      "metadata": {
        "id": "NZOdHOPkSfJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOrWg4mthaji"
      },
      "source": [
        "# train yolov5l on object detection data for 100 epochs with batch size of 80\n",
        "# images are pre-processed to 416 x 416 size\n",
        "# data.yaml contains location of train and validation data\n",
        "# configuration of neural network is in custom_yolov5l.yaml\n",
        "# weights stored at /content/yolov5/runs/exp2/weights/best.pt\n",
        "# time performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 64 --epochs 100 --data './data.yaml' --cfg ./models/custom_yolov5l.yaml --weights '' --device 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm8CED0uuNnD"
      },
      "source": [
        "## Evaluate Custom YOLOv5 Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIrHFw6bjDSj"
      },
      "source": [
        "# start tensorboard\n",
        "# launch after starting training\n",
        "# logs saved in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/yolov5/runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLnXzlpUu1Cj"
      },
      "source": [
        "## Visualize Training Data with Labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCCEpH6GvCgf"
      },
      "source": [
        "# display ground truth data\n",
        "# ground truth/training data available at /content/yolov5/runs/train/exp2/val_batch0_labels.jpg \n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "im = Image.open('/content/yolov5/runs/train/exp2/val_batch0_labels.jpg')\n",
        "Image.Image.show(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk_3YQYKvF8_"
      },
      "source": [
        "# print out augmented training data\n",
        "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
        "im = Image.open('/content/yolov5/runs/train/exp2/train_batch0.jpg')\n",
        "Image.Image.show(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b1D1LnywCXC"
      },
      "source": [
        "# Run Inference With Trained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ6lwf-7wEoX"
      },
      "source": [
        "# use the best weights\n",
        "# final weights stored at /content/yolov5/runs/train/exp2/weights/best.pt\n",
        "%cd /content/yolov5/\n",
        "!python detect.py --weights /content/yolov5/runs/train/exp2/weights/best.pt --img 416 --conf 0.4 --source ./test/images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B4237Tgwh7J"
      },
      "source": [
        "### Check the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vwH78ymwgjh"
      },
      "source": [
        "# display inference on all test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_udyCW9xDkw"
      },
      "source": [
        "## Export Trained Weights for Future Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bFZwDjuwmhG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cp /content/yolov5/runs/train/exp2/weights/best.pt /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb-tjPbJ3dOR"
      },
      "source": [
        "# Split Test Video into Frames and Run Inference with Trained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmjA85UlpVt3"
      },
      "source": [
        "# Change video path as needed\n",
        "vidObj = cv2.VideoCapture('/content/gdrive/My Drive/KelpandFish_short.mp4')\n",
        "\n",
        "numFrames = 0\n",
        "success = 1\n",
        "\n",
        "# create Drive directory to store files before running this chunk of code\n",
        "# rename 'FishKelpFrames' to desired directory name\n",
        "\n",
        "while success:\n",
        "  success, image = vidObj.read()\n",
        "\n",
        "  if(success == 1):\n",
        "    newImg = cv2.resize(image, (416, 416))\n",
        "    cv2.imwrite(\"/content/gdrive/MyDrive/FishKelpFrames/frame%s.jpg\" % str(numFrames).zfill(4), newImg)\n",
        "    numFrames += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoP4rPBw3u37"
      },
      "source": [
        "# use the best weights\n",
        "# final weights stored at /content/yolov5/runs/train/exp2/weights/best.pt\n",
        "%cd /content/yolov5/\n",
        "#!python detect.py --weights /content/yolov5/runs/train/exp2/weights/best.pt --img 416 --conf 0.4 --source /content/gdrive/MyDrive/FishKelpFrames\n",
        "!python detect.py --weights /content/gdrive/MyDrive/best.pt --img 416 --conf 0.4 --source /content/gdrive/MyDrive/FishKelpFrames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnPeLtzg5Q4s"
      },
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp5/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Video from Detected Images"
      ],
      "metadata": {
        "id": "T5u5ATG538nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frameSize = (416, 416)\n",
        "out = cv2.VideoWriter('/content/gdrive/MyDrive/predictionVideo.avi', cv2.VideoWriter_fourcc(*'DIVX'), 60, frameSize)\n",
        "\n",
        "for filename in glob.glob('/content/yolov5/runs/detect/exp5/*.jpg'):\n",
        "  img = cv2.imread(filename)\n",
        "  out.write(img)\n",
        "\n",
        "out.release()"
      ],
      "metadata": {
        "id": "PclT8tVA4DkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L6WNRVyBrzB"
      },
      "source": [
        "# Export Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou_ShOzJBlJd"
      },
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "%cp -r /content/yolov5 /content/gdrive/MyDrive/Augmented\\ Resized\\ YOLOv5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try With A Different Video"
      ],
      "metadata": {
        "id": "vS__caR8J41f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vidObj = cv2.VideoCapture('/content/gdrive/My Drive/Fish2_short.mp4')\n",
        "\n",
        "numFrames = 0\n",
        "success = 1\n",
        "\n",
        "while success:\n",
        "  success, image = vidObj.read()\n",
        "\n",
        "  if(success == 1):\n",
        "    newImg = cv2.resize(image, (416, 416))\n",
        "    cv2.imwrite(\"/content/gdrive/MyDrive/FishKelpFrames2/frame%s.jpg\" % str(numFrames).zfill(4), newImg)\n",
        "    numFrames += 1"
      ],
      "metadata": {
        "id": "BR5WlV41J4IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the best weights!\n",
        "# Final weights will be by-default stored at /content/yolov5/runs/train/exp2/weights/best.pt\n",
        "%cd /content/yolov5/\n",
        "#!python detect.py --weights /content/yolov5/runs/train/exp2/weights/best.pt --img 416 --conf 0.4 --source /content/gdrive/MyDrive/FishKelpFrames\n",
        "!python detect.py --weights /content/gdrive/MyDrive/best.pt --img 416 --conf 0.4 --source /content/gdrive/MyDrive/FishKelpFrames2"
      ],
      "metadata": {
        "id": "G6NAe2fhGUkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp4/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "mbsntXgPGah1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try With Yet One More Video"
      ],
      "metadata": {
        "id": "Z2nat7ijKA3H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0VVwj02xJ_7X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}